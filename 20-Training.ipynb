{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20-Training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP120hWuOUzvweJx4rF+ywr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ew81YmV0Qcf","executionInfo":{"status":"ok","timestamp":1650341461885,"user_tz":300,"elapsed":14870,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"99f38485-e106-4cef-87da-d7510ffc11e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","cur_path = \"./gdrive/Othercomputers/Desktop_Vivian/twitter_hashtag_recommendor/\"\n","os.chdir(cur_path)\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWoFcuuC46vK","executionInfo":{"status":"ok","timestamp":1650341463505,"user_tz":300,"elapsed":493,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"c05552ca-dfbf-41b8-c0a5-65d3c938a77e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Othercomputers/Desktop_Vivian/twitter_hashtag_recommendor\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","# !pip install --upgrade torch torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KIZOev08ArA","executionInfo":{"status":"ok","timestamp":1650341474025,"user_tz":300,"elapsed":8405,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"13666465-c728-4b57-e680-261fcb2714c3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 44.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"]}]},{"cell_type":"code","source":["! curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n","! sudo apt-get install git-lfs\n","! git lfs install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Km3wdvZgcRh","executionInfo":{"status":"ok","timestamp":1650341501437,"user_tz":300,"elapsed":27418,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"8af2c6eb-41ed-4c21-aee1-a2f57f74819a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected operating system as Ubuntu/bionic.\n","Checking for curl...\n","Detected curl...\n","Checking for gpg...\n","Detected gpg...\n","Running apt-get update... done.\n","Installing apt-transport-https... done.\n","Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n","Importing packagecloud gpg key... done.\n","Running apt-get update... done.\n","\n","The repository is setup! You can now install packages.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  git-lfs\n","0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 6,800 kB of archives.\n","After this operation, 15.3 MB of additional disk space will be used.\n","Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 3.1.2 [6,800 kB]\n","Fetched 6,800 kB in 1s (13.2 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package git-lfs.\n","(Reading database ... 155459 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_3.1.2_amd64.deb ...\n","Unpacking git-lfs (3.1.2) ...\n","Setting up git-lfs (3.1.2) ...\n","Git LFS initialized.\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Updated Git hooks.\n","Git LFS initialized.\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForMaskedLM, BertModel\n","import torch\n","print(torch.__version__)\n","\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahNwlBegUiXh","executionInfo":{"status":"ok","timestamp":1650341512177,"user_tz":300,"elapsed":10747,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"3b06e4b4-4f00-497d-add4-f69b3edbccc8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu111\n"]}]},{"cell_type":"code","source":["import string as st\n","import nltk \n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","def pre_processing(text, punc):\n","    texts = text.split()\n","    a = []\n","    for t in texts:\n","      for n in t:\n","        if n in punc:\n","          t = t.replace(n, \"\")\n","      s = t.lower()\n","      a.append(s)\n","    return ' '.join(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6ImYRb361N3","executionInfo":{"status":"ok","timestamp":1650341522687,"user_tz":300,"elapsed":3052,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"ed45b625-c1bd-4e99-a387-67ee7eb46f50"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","labeled_tweet = pd.read_csv(\"./data/labeled_tweet2.csv\")\n","labeled_text = [str(s) for s in labeled_tweet['cleaned_tweet'].tolist()]\n","\n","punc = '''!\"@$%&\\'()*+,-./:;<=>?\\\\^_`{|}[]~'''\n","labeled_text = [pre_processing(t, punc) for t in labeled_text]\n","\n","train_text, test_text = train_test_split(labeled_text, random_state=2018, test_size=0.2)\n"],"metadata":{"id":"5Krc6hqlUlnI","executionInfo":{"status":"ok","timestamp":1650345115799,"user_tz":300,"elapsed":383,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["## Add special tokens (hashtags)"],"metadata":{"id":"8hw-xLO2RGtv"}},{"cell_type":"code","source":["special_tokens = {}\n","for t in labeled_text:\n","  for s in t.split():\n","    if s.startswith('#'):\n","      if s in special_tokens:\n","        special_tokens[s] += 1\n","      else:\n","        special_tokens[s] = 1\n","import operator\n","sp_tks = list(dict(sorted(special_tokens.items(), key=operator.itemgetter(1),reverse=True)).keys())[:1000]"],"metadata":{"id":"JyaSge9NKsgr","executionInfo":{"status":"ok","timestamp":1650345127443,"user_tz":300,"elapsed":191,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(sp_tks).to_csv(\"./special_tokens.csv\", header=False)"],"metadata":{"id":"8sWYgrKXWcBw","executionInfo":{"status":"ok","timestamp":1650347127438,"user_tz":300,"elapsed":132,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', additional_special_tokens=sp_tks)\n","# tokenizer.save_pretrained('./bert_twitter_hashtag/')\n","# model = BertModel.from_pretrained(\"bert-base-uncased\")\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTLV_scBOR-0","executionInfo":{"status":"ok","timestamp":1650345134791,"user_tz":300,"elapsed":5636,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"31d3d1d2-5163-4f38-b255-9ea2cb97fdff"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Adding #mondaythoughts to the vocabulary\n","Adding #mondaymotivation to the vocabulary\n","Adding #bostonmarathon to the vocabulary\n","Adding #thefirstlady to the vocabulary\n","Adding #thebatman to the vocabulary\n","Adding #kandiandthegang to the vocabulary\n","Adding #katg to the vocabulary\n","Adding #easter to the vocabulary\n","Adding #mondayvibes to the vocabulary\n","Adding #eastermonday to the vocabulary\n","Adding #boston to the vocabulary\n","Adding #running to the vocabulary\n","Adding #marathon to the vocabulary\n","Adding #batman to the vocabulary\n","Adding #monday to the vocabulary\n","Adding #runto125 to the vocabulary\n","Adding #mondaymorning to the vocabulary\n","Adding #art to the vocabulary\n","Adding #hbomax to the vocabulary\n","Adding #mondaymood to the vocabulary\n","Adding #bostonathletemagazine to the vocabulary\n","Adding #bostonstrong to the vocabulary\n","Adding #quote to the vocabulary\n","Adding #quotes to the vocabulary\n","Adding #run to the vocabulary\n","Adding #music to the vocabulary\n","Adding #bostonathlete to the vocabulary\n","Adding #homedecor to the vocabulary\n","Adding #antiques to the vocabulary\n","Adding #xochella to the vocabulary\n","Adding #easter2022 to the vocabulary\n","Adding #interiordesign to the vocabulary\n","Adding #rediscova to the vocabulary\n","Adding #tableware to the vocabulary\n","Adding #motivation to the vocabulary\n","Adding #coachella to the vocabulary\n","Adding #love to the vocabulary\n","Adding #runboston to the vocabulary\n","Adding #oldladygang to the vocabulary\n","Adding #boston126 to the vocabulary\n","Adding #vintage to the vocabulary\n","Adding #onthisdaysports to the vocabulary\n","Adding #dc to the vocabulary\n","Adding #groovevinyl to the vocabulary\n","Adding #giftideas to the vocabulary\n","Adding #mondaymotivaton to the vocabulary\n","Adding #bostonrunner to the vocabulary\n","Adding #showtime to the vocabulary\n","Adding #robertpattinson to the vocabulary\n","Adding #dccomics to the vocabulary\n","Adding #inspiration to the vocabulary\n","Adding #motivationalquotes to the vocabulary\n","Adding #theriddler to the vocabulary\n","Adding #happyeaster to the vocabulary\n","Adding #godmorningmonday to the vocabulary\n","Adding #nationalpetday to the vocabulary\n","Adding #records to the vocabulary\n","Adding #nowspinning to the vocabulary\n","Adding #nationalpetsday to the vocabulary\n","Adding #interiorstyling to the vocabulary\n","Adding #michelleobama to the vocabulary\n","Adding #interiors to the vocabulary\n","Adding #studioglass to the vocabulary\n","Adding #ceramics to the vocabulary\n","Adding #quotestoliveby to the vocabulary\n","Adding #nowplaying to the vocabulary\n","Adding #mentalhealth to the vocabulary\n","Adding #trending to the vocabulary\n","Adding #marathonmonday to the vocabulary\n","Adding #sustainable to the vocabulary\n","Adding #glassware to the vocabulary\n","Adding #motivationmonday to the vocabulary\n","Adding #runner to the vocabulary\n","Adding #worldheritageday to the vocabulary\n","Adding #riddler to the vocabulary\n","Adding #success to the vocabulary\n","Adding #youtube to the vocabulary\n","Adding #shareinspirequotes to the vocabulary\n","Adding #whatsapp to the vocabulary\n","Adding #webseries to the vocabulary\n","Adding #etsystrike to the vocabulary\n","Adding #life to the vocabulary\n","Adding #health to the vocabulary\n","Adding #whatsappstatus to the vocabulary\n","Adding #fun to the vocabulary\n","Adding #dramacourtblog to the vocabulary\n","Adding #rhoa to the vocabulary\n","Adding #violadavis to the vocabulary\n","Adding #ukraine to the vocabulary\n","Adding #podcast to the vocabulary\n","Adding #runchat to the vocabulary\n","Adding #muyanku to the vocabulary\n","Adding #bankholiday to the vocabulary\n","Adding #catwoman to the vocabulary\n","Adding #quoteoftheday to the vocabulary\n","Adding #theinnercircle to the vocabulary\n","Adding #writingcommunity to the vocabulary\n","Adding #runners to the vocabulary\n","Adding #fitness to the vocabulary\n","Adding #nft to the vocabulary\n","Adding #business to the vocabulary\n","Adding #coachella2022 to the vocabulary\n","Adding #joker to the vocabulary\n","Adding #ferngully to the vocabulary\n","Adding #mondayblues to the vocabulary\n","Adding #michellepfeiffer to the vocabulary\n","Adding #kandiandtodd to the vocabulary\n","Adding #gilliananderson to the vocabulary\n","Adding #marathontraining to the vocabulary\n","Adding #congo to the vocabulary\n","Adding #tbt to the vocabulary\n","Adding #cskvsgt to the vocabulary\n","Adding #jadensmith to the vocabulary\n","Adding #goodmorning to the vocabulary\n","Adding #quotur to the vocabulary\n","Adding #tca22 to the vocabulary\n","Adding #aprilsblossomsehun to the vocabulary\n","Adding #dceu to the vocabulary\n","Adding #nfts to the vocabulary\n","Adding #usa to the vocabulary\n","Adding #covid19 to the vocabulary\n","Adding #movies to the vocabulary\n","Adding #theweeknd to the vocabulary\n","Adding #bostonsports to the vocabulary\n","Adding #wellness to the vocabulary\n","Adding #redsox to the vocabulary\n","Adding #thebestcomedyseeninyears to the vocabulary\n","Adding #cryptocurrency to the vocabulary\n","Adding #percyjackson to the vocabulary\n","Adding #nftcommunity to the vocabulary\n","Adding #photography to the vocabulary\n","Adding #blackownedbusiness to the vocabulary\n","Adding #goals to the vocabulary\n","Adding #nature to the vocabulary\n","Adding #fridayfeeling to the vocabulary\n","Adding #crewlove to the vocabulary\n","Adding #influencer to the vocabulary\n","Adding #fanart to the vocabulary\n","Adding #nintendoswitch to the vocabulary\n","Adding #happyholidays to the vocabulary\n","Adding #ayaka to the vocabulary\n","Adding #motivational to the vocabulary\n","Adding #baa to the vocabulary\n","Adding #thegreathouserevival to the vocabulary\n","Adding #etsy to the vocabulary\n","Adding #extraordinaryjoe3 to the vocabulary\n","Adding #brucewayne to the vocabulary\n","Adding #restorethesnyderverse to the vocabulary\n","Adding #spring to the vocabulary\n","Adding #hope to the vocabulary\n","Adding #thefirstladys to the vocabulary\n","Adding #thebatmanmovie to the vocabulary\n","Adding #gotham to the vocabulary\n","Adding #twitter to the vocabulary\n","Adding #poetry to the vocabulary\n","Adding #acnh to the vocabulary\n","Adding #bravo to the vocabulary\n","Adding #mindfulness to the vocabulary\n","Adding #travel to the vocabulary\n","Adding #wbz to the vocabulary\n","Adding #postpolio to the vocabulary\n","Adding #chicagomarathon to the vocabulary\n","Adding #traveltuesday to the vocabulary\n","Adding #batmanenhbomax to the vocabulary\n","Adding #mattreeves to the vocabulary\n","Adding #pauldano to the vocabulary\n","Adding #willsmith to the vocabulary\n","Adding #oscars to the vocabulary\n","Adding #raypowernigeria to the vocabulary\n","Adding #healing to the vocabulary\n","Adding #happymonday to the vocabulary\n","Adding #newweek to the vocabulary\n","Adding #joeysdream to the vocabulary\n","Adding #bostonmarathon2021 to the vocabulary\n","Adding #leadership to the vocabulary\n","Adding #delhiriots to the vocabulary\n","Adding #influencermarketing to the vocabulary\n","Adding #morbius to the vocabulary\n","Adding #theriddlerfanart to the vocabulary\n","Adding #digitalart to the vocabulary\n","Adding #artist to the vocabulary\n","Adding #crypto to the vocabulary\n","Adding #books to the vocabulary\n","Adding #family to the vocabulary\n","Adding #happiness to the vocabulary\n","Adding #blessed to the vocabulary\n","Adding #runningmotivation to the vocabulary\n","Adding #positivevibes to the vocabulary\n","Adding #tiktok to the vocabulary\n","Adding #trauma to the vocabulary\n","Adding #tfl to the vocabulary\n","Adding #13thfreepoliocamp to the vocabulary\n","Adding #riddlerfanart to the vocabulary\n","Adding #wwe to the vocabulary\n","Adding #bravotv to the vocabulary\n","Adding #easterweekend to the vocabulary\n","Adding #training to the vocabulary\n","Adding #motivationalmonday to the vocabulary\n","Adding #joy to the vocabulary\n","Adding #fastforwardwithslice to the vocabulary\n","Adding #inspirationalquotes to the vocabulary\n","Adding #batmannahbomax to the vocabulary\n","Adding #warnerbros to the vocabulary\n","Adding #nba to the vocabulary\n","Adding #olg to the vocabulary\n","Adding #mondayquotes to the vocabulary\n","Adding #mindbody to the vocabulary\n","Adding #podcasting to the vocabulary\n","Adding #russia to the vocabulary\n","Adding #money to the vocabulary\n","Adding #happy to the vocabulary\n","Adding #selfcare to the vocabulary\n","Adding #mondaymotivations to the vocabulary\n","Adding #patriotsday to the vocabulary\n","Adding #adidas to the vocabulary\n","Adding #ayato to the vocabulary\n","Adding #sonicmovie2 to the vocabulary\n","Adding #food to the vocabulary\n","Adding #amctheatres to the vocabulary\n","Adding #comics to the vocabulary\n","Adding #news to the vocabulary\n","Adding #coffee to the vocabulary\n","Adding #scifi to the vocabulary\n","Adding #africa to the vocabulary\n","Adding #work to the vocabulary\n","Adding #runnersofinstagram to the vocabulary\n","Adding #tvshow to the vocabulary\n","Adding #factsaboutchristianity to the vocabulary\n","Adding #thoughtoftheday to the vocabulary\n","Adding #movie to the vocabulary\n","Adding #drawing to the vocabulary\n","Adding #blog to the vocabulary\n","Adding #boxoffice to the vocabulary\n","Adding #book to the vocabulary\n","Adding #catsoftwitter to the vocabulary\n","Adding #faith to the vocabulary\n","Adding #adidasrunning to the vocabulary\n","Adding #eleanorroosevelt to the vocabulary\n","Adding #lakhimpurkheri to the vocabulary\n","Adding #thebatmanfanart to the vocabulary\n","Adding #theflash to the vocabulary\n","Adding #ebay to the vocabulary\n","Adding #drama to the vocabulary\n","Adding #btc to the vocabulary\n","Adding #kenya to the vocabulary\n","Adding #holiday to the vocabulary\n","Adding #mindset to the vocabulary\n","Adding #qotd to the vocabulary\n","Adding #bettyford to the vocabulary\n","Adding #thinkbigsundaywithmarsha to the vocabulary\n","Adding #quarantine to the vocabulary\n","Adding #mciliv to the vocabulary\n","Adding #cats to the vocabulary\n","Adding #wordle303 to the vocabulary\n","Adding #moonknight to the vocabulary\n","Adding #riddlebat to the vocabulary\n","Adding #video to the vocabulary\n","Adding #dogsoftwitter to the vocabulary\n","Adding #vegan to the vocabulary\n","Adding #legendoftheseadevils to the vocabulary\n","Adding #growth to the vocabulary\n","Adding #massachusetts to the vocabulary\n","Adding #deathpenalty to the vocabulary\n","Adding #medalmonday to the vocabulary\n","Adding #positivity to the vocabulary\n","Adding #wisdom to the vocabulary\n","Adding #positivevibesonly to the vocabulary\n","Adding #mohammedali to the vocabulary\n","Adding #photo to the vocabulary\n","Adding #postlo to the vocabulary\n","Adding #mondayinspiration to the vocabulary\n","Adding #fitnessfriday to the vocabulary\n","Adding #edwardnashton to the vocabulary\n","Adding #superman to the vocabulary\n","Adding #kandiburruss to the vocabulary\n","Adding #easterholidays to the vocabulary\n","Adding #inspire to the vocabulary\n","Adding #etsyshop to the vocabulary\n","Adding #entrepreneur to the vocabulary\n","Adding #community to the vocabulary\n","Adding #bulls to the vocabulary\n","Adding #genshinimpact to the vocabulary\n","Adding #artwork to the vocabulary\n","Adding #gaming to the vocabulary\n","Adding #hbo to the vocabulary\n","Adding #90dayfiance to the vocabulary\n","Adding #comedy to the vocabulary\n","Adding #zoekravitz to the vocabulary\n","Adding #jesus to the vocabulary\n","Adding #reading to the vocabulary\n","Adding #horror to the vocabulary\n","Adding #trump to the vocabulary\n","Adding #rollswat to the vocabulary\n","Adding #bitcoin to the vocabulary\n","Adding #aflhawkscats to the vocabulary\n","Adding #competition to the vocabulary\n","Adding #261fearless to the vocabulary\n","Adding #firstlady to the vocabulary\n","Adding #kashmir to the vocabulary\n","Adding #kamisatoayaka to the vocabulary\n","Adding #twitch to the vocabulary\n","Adding #comic to the vocabulary\n","Adding #thelostcity to the vocabulary\n","Adding #funny to the vocabulary\n","Adding #artistontwitter to the vocabulary\n","Adding #shopmycloset to the vocabulary\n","Adding #dog to the vocabulary\n","Adding #viral to the vocabulary\n","Adding #lifestyle to the vocabulary\n","Adding #themasters to the vocabulary\n","Adding #ukrainewar to the vocabulary\n","Adding #kandi to the vocabulary\n","Adding #education to the vocabulary\n","Adding #nigeria to the vocabulary\n","Adding #peace to the vocabulary\n","Adding #bostonmarathon2022 to the vocabulary\n","Adding #pandemic to the vocabulary\n","Adding #wheelchairracer to the vocabulary\n","Adding #womenownedbusiness to the vocabulary\n","Adding #kids to the vocabulary\n","Adding #mondayreport to the vocabulary\n","Adding #marvel to the vocabulary\n","Adding #uk to the vocabulary\n","Adding #writerslift to the vocabulary\n","Adding #everythingeverywhereallatonce to the vocabulary\n","Adding #climatecrisis to the vocabulary\n","Adding #canada to the vocabulary\n","Adding #new to the vocabulary\n","Adding #radio to the vocabulary\n","Adding #amwriting to the vocabulary\n","Adding #jadapinkettsmith to the vocabulary\n","Adding #women to the vocabulary\n","Adding #beautiful to the vocabulary\n","Adding #abbottwmm to the vocabulary\n","Adding #visualization to the vocabulary\n","Adding #healthcare to the vocabulary\n","Adding #melaniatrump to the vocabulary\n","Adding #startup to the vocabulary\n","Adding #ufc273 to the vocabulary\n","Adding #doctorwho to the vocabulary\n","Adding #comicbooks to the vocabulary\n","Adding #thedarkknight to the vocabulary\n","Adding #eastersunday to the vocabulary\n","Adding #nftart to the vocabulary\n","Adding #netflix to the vocabulary\n","Adding #digitalmarketing to the vocabulary\n","Adding #90dayfiancetellall to the vocabulary\n","Adding #nonprofit to the vocabulary\n","Adding #easterbunny to the vocabulary\n","Adding #sports to the vocabulary\n","Adding #adidaswomen to the vocabulary\n","Adding #peloton to the vocabulary\n","Adding #indigenouspeoplesday to the vocabulary\n","Adding #205live to the vocabulary\n","Adding #successtrain to the vocabulary\n","Adding #quotesoftheday to the vocabulary\n","Adding #thoughts to the vocabulary\n","Adding #wweraw to the vocabulary\n","Adding #ad to the vocabulary\n","Adding #live to the vocabulary\n","Adding #verzuz to the vocabulary\n","Adding #meditation to the vocabulary\n","Adding #americanidol to the vocabulary\n","Adding #learning to the vocabulary\n","Adding #instagram to the vocabulary\n","Adding #amazon to the vocabulary\n","Adding #batmanfanart to the vocabulary\n","Adding #eth to the vocabulary\n","Adding #tunein to the vocabulary\n","Adding #cxoachella to the vocabulary\n","Adding #india to the vocabulary\n","Adding #history to the vocabulary\n","Adding #realestate to the vocabulary\n","Adding #deals to the vocabulary\n","Adding #grateful to the vocabulary\n","Adding #mentalhealthmatters to the vocabulary\n","Adding #swedishhousemafia to the vocabulary\n","Adding #suicideprevention to the vocabulary\n","Adding #selflove to the vocabulary\n","Adding #bostonathletes to the vocabulary\n","Adding #seered to the vocabulary\n","Adding #dogs to the vocabulary\n","Adding #cosplay to the vocabulary\n","Adding #arkham to the vocabulary\n","Adding #twitchstreamer to the vocabulary\n","Adding #tuesdayvibe to the vocabulary\n","Adding #gratitude to the vocabulary\n","Adding #stockmarket to the vocabulary\n","Adding #pets to the vocabulary\n","Adding #london to the vocabulary\n","Adding #bankholidaymonday to the vocabulary\n","Adding #flowers to the vocabulary\n","Adding #morningmotivation to the vocabulary\n","Adding #athletics to the vocabulary\n","Adding #nbaplayoffs to the vocabulary\n","Adding #wcvb to the vocabulary\n","Adding #fundraising to the vocabulary\n","Adding #flotus to the vocabulary\n","Adding #maga to the vocabulary\n","Adding #showtimeseries to the vocabulary\n","Adding #thekingdom to the vocabulary\n","Adding #njpw to the vocabulary\n","Adding #kindnessmatters to the vocabulary\n","Adding #god to the vocabulary\n","Adding #fitnessmotivation to the vocabulary\n","Adding #makeyourownlane to the vocabulary\n","Adding #joytrain to the vocabulary\n","Adding #saintrampaljiquotes to the vocabulary\n","Adding #iam to the vocabulary\n","Adding #osinbajodeclares to the vocabulary\n","Adding #spdc to the vocabulary\n","Adding #bvs to the vocabulary\n","Adding #spidermannowayhome to the vocabulary\n","Adding #streaming to the vocabulary\n","Adding #hollywood to the vocabulary\n","Adding #fantasticbeasts to the vocabulary\n","Adding #writers to the vocabulary\n","Adding #batgirl to the vocabulary\n","Adding #facts to the vocabulary\n","Adding #goodfriday to the vocabulary\n","Adding #newmusic to the vocabulary\n","Adding #friends to the vocabulary\n","Adding #rt to the vocabulary\n","Adding #hiphop to the vocabulary\n","Adding #bekind to the vocabulary\n","Adding #dogsoftwittter to the vocabulary\n","Adding #weather to the vocabulary\n","Adding #nevergiveup to the vocabulary\n","Adding #entrepreneurship to the vocabulary\n","Adding #mlb to the vocabulary\n","Adding #dzhokhartsarnaev to the vocabulary\n","Adding #tsarnaev to the vocabulary\n","Adding #thecrown to the vocabulary\n","Adding #thefirstladyofprofessionalwrestling to the vocabulary\n","Adding #smackdown to the vocabulary\n","Adding #roh to the vocabulary\n","Adding #tna to the vocabulary\n","Adding #impactwrestling to the vocabulary\n","Adding #mrpresident to the vocabulary\n","Adding #startups to the vocabulary\n","Adding #goldenhearts to the vocabulary\n","Adding #thegoat to the vocabulary\n","Adding #bullsnation to the vocabulary\n","Adding #kgf2 to the vocabulary\n","Adding #cinema to the vocabulary\n","Adding #illustration to the vocabulary\n","Adding #sunday to the vocabulary\n","Adding #tvseries to the vocabulary\n","Adding #poem to the vocabulary\n","Adding #climateaction to the vocabulary\n","Adding #biden to the vocabulary\n","Adding #writing to the vocabulary\n","Adding #marketing to the vocabulary\n","Adding #donate to the vocabulary\n","Adding #kayrodcast to the vocabulary\n","Adding #gop to the vocabulary\n","Adding #research to the vocabulary\n","Adding #celebration to the vocabulary\n","Adding #football to the vocabulary\n","Adding #mondays to the vocabulary\n","Adding #gardening to the vocabulary\n","Adding #italy to the vocabulary\n","Adding #kindness to the vocabulary\n","Adding #amateurradio to the vocabulary\n","Adding #entrepreneurs to the vocabulary\n","Adding #letsgo to the vocabulary\n","Adding #bospoli to the vocabulary\n","Adding #bq to the vocabulary\n","Adding #read to the vocabulary\n","Adding #handcraftedsoap to the vocabulary\n","Adding #handcrafted to the vocabulary\n","Adding #wildlife to the vocabulary\n","Adding #naturelovers to the vocabulary\n","Adding #morningvibes to the vocabulary\n","Adding #inspirational to the vocabulary\n","Adding #mondayfunday to the vocabulary\n","Adding #mondayblogs to the vocabulary\n","Adding #theogbueshioneofsports to the vocabulary\n","Adding #connectingmanyvoices to the vocabulary\n","Adding #caruso to the vocabulary\n","Adding #nbaplayoffs2022 to the vocabulary\n","Adding #foodie to the vocabulary\n","Adding #harleyquinn to the vocabulary\n","Adding #instagood to the vocabulary\n","Adding #entertainment to the vocabulary\n","Adding #youtuber to the vocabulary\n","Adding #thebatman2022 to the vocabulary\n","Adding #film to the vocabulary\n","Adding #spotify to the vocabulary\n","Adding #disney to the vocabulary\n","Adding #like to the vocabulary\n","Adding #socialmedia to the vocabulary\n","Adding #cxochella to the vocabulary\n","Adding #games to the vocabulary\n","Adding #climateactionnow to the vocabulary\n","Adding #writerslife to the vocabulary\n","Adding #fashion to the vocabulary\n","Adding #style to the vocabulary\n","Adding #catsontwitter to the vocabulary\n","Adding #metaverse to the vocabulary\n","Adding #blockchain to the vocabulary\n","Adding #drc to the vocabulary\n","Adding #april to the vocabulary\n","Adding #bankholidayweekend to the vocabulary\n","Adding #heisrisen to the vocabulary\n","Adding #workout to the vocabulary\n","Adding #free to the vocabulary\n","Adding #goodmorningtwitterworld to the vocabulary\n","Adding #gym to the vocabulary\n","Adding #christianity to the vocabulary\n","Adding #ai to the vocabulary\n","Adding #hamradio to the vocabulary\n","Adding #marathonrunner to the vocabulary\n","Adding #possibilities to the vocabulary\n","Adding #nationalpoetrymonth to the vocabulary\n","Adding #covid to the vocabulary\n","Adding #dreams to the vocabulary\n","Adding #recovery to the vocabulary\n","Adding #technology to the vocabulary\n","Adding #nycmarathon to the vocabulary\n","Adding #vootselect to the vocabulary\n","Adding #thefirstladytvshow to the vocabulary\n","Adding #handcraftedbathandbody to the vocabulary\n","Adding #runwithoutlimit to the vocabulary\n","Adding #nakedspiritrunners to the vocabulary\n","Adding #travelguide to the vocabulary\n","Adding #inspirationalquote to the vocabulary\n","Adding #chooselove to the vocabulary\n","Adding #truth to the vocabulary\n","Adding #kamisatoayato to the vocabulary\n","Adding #cute to the vocabulary\n","Adding #anime to the vocabulary\n","Adding #ambulance to the vocabulary\n","Adding #hbogo to the vocabulary\n","Adding #robertpattison to the vocabulary\n","Adding #dcuniverse to the vocabulary\n","Adding #films to the vocabulary\n","Adding #losangeles to the vocabulary\n","Adding #zacksnydersjusticeleague to the vocabulary\n","Adding #bluray to the vocabulary\n","Adding #digitalasset to the vocabulary\n","Adding #smallstreamer to the vocabulary\n","Adding #3 to the vocabulary\n","Adding #putin to the vocabulary\n","Adding #rock to the vocabulary\n","Adding #support to the vocabulary\n","Adding #russian to the vocabulary\n","Adding #jungkook to the vocabulary\n","Adding #birds to the vocabulary\n","Adding #blackpink to the vocabulary\n","Adding #soul to the vocabulary\n","Adding #willandchris to the vocabulary\n","Adding #chrisrock to the vocabulary\n","Adding #memes to the vocabulary\n","Adding #cartoon to the vocabulary\n","Adding #us to the vocabulary\n","Adding #neneleakes to the vocabulary\n","Adding #wordle296 to the vocabulary\n","Adding #tech to the vocabulary\n","Adding #rdcquestionauxsorciers to the vocabulary\n","Adding #weekend to the vocabulary\n","Adding #naturephotography to the vocabulary\n","Adding #shopping to the vocabulary\n","Adding #sale to the vocabulary\n","Adding #sunrise to the vocabulary\n","Adding #eastereggs to the vocabulary\n","Adding #orluisbleeding to the vocabulary\n","Adding #tv to the vocabulary\n","Adding #home to the vocabulary\n","Adding #mentalhealthawareness to the vocabulary\n","Adding #hint to the vocabulary\n","Adding #gujarattitans to the vocabulary\n","Adding #boston25 to the vocabulary\n","Adding #roadtoboston to the vocabulary\n","Adding #charityrunner to the vocabulary\n","Adding #bqchat to the vocabulary\n","Adding #redsoxnation to the vocabulary\n","Adding #cancer to the vocabulary\n","Adding #fbi to the vocabulary\n","Adding #hopkinton to the vocabulary\n","Adding #belarus to the vocabulary\n","Adding #teambaycove to the vocabulary\n","Adding #ptsd to the vocabulary\n","Adding #supremecourt to the vocabulary\n","Adding #mepolitics to the vocabulary\n","Adding #volunteer to the vocabulary\n","Adding #gamechangers to the vocabulary\n","Adding #americafirst to the vocabulary\n","Adding #runcoach to the vocabulary\n","Adding #report4charlie to the vocabulary\n","Adding #python to the vocabulary\n","Adding #facebook to the vocabulary\n","Adding #teamwork to the vocabulary\n","Adding #jobs to the vocabulary\n","Adding #boston2021 to the vocabulary\n","Adding #respect to the vocabulary\n","Adding #melanomaawareness to the vocabulary\n","Adding #ipl2022 to the vocabulary\n","Adding #series to the vocabulary\n","Adding #themiracle to the vocabulary\n","Adding #healthy to the vocabulary\n","Adding #raw to the vocabulary\n","Adding #dceaglecam to the vocabulary\n","Adding #focus to the vocabulary\n","Adding #motivationalquote to the vocabulary\n","Adding #royalconnection to the vocabulary\n","Adding #ebook to the vocabulary\n","Adding #stress to the vocabulary\n","Adding #wnbadraft to the vocabulary\n","Adding #cat to the vocabulary\n","Adding #game to the vocabulary\n","Adding #timcurry to the vocabulary\n","Adding #bettercallsaul to the vocabulary\n","Adding #thejoker to the vocabulary\n","Adding #thebatmans to the vocabulary\n","Adding #arkhamapril to the vocabulary\n","Adding #wonderwoman to the vocabulary\n","Adding #robin to the vocabulary\n","Adding #blogger to the vocabulary\n","Adding #spiderman to the vocabulary\n","Adding #ambulancemovie to the vocabulary\n","Adding #fatherstumovie to the vocabulary\n","Adding #animals to the vocabulary\n","Adding #batcat to the vocabulary\n","Adding #secretsofdumbledore to the vocabulary\n","Adding #procreate to the vocabulary\n","Adding #everythingeverywhere to the vocabulary\n","Adding #sonicthehedgehog2 to the vocabulary\n","Adding #beauty to the vocabulary\n","Adding #ethereum to the vocabulary\n","Adding #disneyplus to the vocabulary\n","Adding #nftcommmunity to the vocabulary\n","Adding #follow to the vocabulary\n","Adding #videos to the vocabulary\n","Adding #100daysofcode to the vocabulary\n","Adding #theweekend to the vocabulary\n","Adding #clothing to the vocabulary\n","Adding #anxiety to the vocabulary\n","Adding #adhd to the vocabulary\n","Adding #design to the vocabulary\n","Adding #america to the vocabulary\n","Adding #keepgoing to the vocabulary\n","Adding #staysafe to the vocabulary\n","Adding #russiaukrainewar to the vocabulary\n","Adding #rhop to the vocabulary\n","Adding #lamh to the vocabulary\n","Adding #sundayvibes to the vocabulary\n","Adding #rdc to the vocabulary\n","Adding #tanzania to the vocabulary\n","Adding #gameofthrones to the vocabulary\n","Adding #bible to the vocabulary\n","Adding #energy to the vocabulary\n","Adding #positivemindset to the vocabulary\n","Adding #thoughtfortheday to the vocabulary\n","Adding #confidence to the vocabulary\n","Adding #heritage to the vocabulary\n","Adding #strongertogether to the vocabulary\n","Adding #morning to the vocabulary\n","Adding #dirtywater to the vocabulary\n","Adding #brookline to the vocabulary\n","Adding #holyweek to the vocabulary\n","Adding #marathoner to the vocabulary\n","Adding #als to the vocabulary\n","Adding #bomber to the vocabulary\n","Adding #potus to the vocabulary\n","Adding #charity to the vocabulary\n","Adding #youth to the vocabulary\n","Adding #nomeatathlete to the vocabulary\n","Adding #children to the vocabulary\n","Adding #alds to the vocabulary\n","Adding #change to the vocabulary\n","Adding #melanoma to the vocabulary\n","Adding #showtimetvshow to the vocabulary\n","Adding #gift to the vocabulary\n","Adding #donaldtrump to the vocabulary\n","Adding #wcw to the vocabulary\n","Adding #wivesonstrike to the vocabulary\n","Adding #retweet to the vocabulary\n","Adding #mondaythought to the vocabulary\n","Adding #career to the vocabulary\n","Adding #harmony to the vocabulary\n","Adding #fintech to the vocabulary\n","Adding #mondaywisdom to the vocabulary\n","Adding #lifecoach to the vocabulary\n","Adding #nayakashmir to the vocabulary\n","Adding #vibeswithjaf to the vocabulary\n","Adding #springforart to the vocabulary\n","Adding #smile to the vocabulary\n","Adding #iartg to the vocabulary\n","Adding #travelingsamson to the vocabulary\n","Adding #content to the vocabulary\n","Adding #guitar to the vocabulary\n","Adding #rtitbot to the vocabulary\n","Adding #samson to the vocabulary\n","Adding #winningtimehbo to the vocabulary\n","Adding #penguin to the vocabulary\n","Adding #teacher to the vocabulary\n","Adding #peacemaker to the vocabulary\n","Adding #moviereview to the vocabulary\n","Adding #kgfchapter2 to the vocabulary\n","Adding #batmanvsuperman to the vocabulary\n","Adding #podcasts to the vocabulary\n","Adding #dcfandome to the vocabulary\n","Adding #tvtime to the vocabulary\n","Adding #lisa to the vocabulary\n","Adding #makethebatfleckmovie to the vocabulary\n","Adding #sketch to the vocabulary\n","Adding #podcastandchill to the vocabulary\n","Adding #draw to the vocabulary\n","Adding #comicart to the vocabulary\n","Adding #tdk to the vocabulary\n","Adding #streamer to the vocabulary\n","Adding #2 to the vocabulary\n","Adding #lol to the vocabulary\n","Adding #spotifypodcasts to the vocabulary\n","Adding #listen to the vocabulary\n","Adding #weeknd to the vocabulary\n","Adding #outoftime to the vocabulary\n","Adding #listenlive to the vocabulary\n","Adding #weightloss to the vocabulary\n","Adding #romance to the vocabulary\n","Adding #innovation to the vocabulary\n","Adding #celtics to the vocabulary\n","Adding #soundcloud to the vocabulary\n","Adding #singer to the vocabulary\n","Adding #hilarious to the vocabulary\n","Adding #fauci to the vocabulary\n","Adding #powerforce to the vocabulary\n","Adding #blacktwitter to the vocabulary\n","Adding #uganda to the vocabulary\n","Adding #ethiopia to the vocabulary\n","Adding #poems to the vocabulary\n","Adding #germany to the vocabulary\n","Adding #holidays to the vocabulary\n","Adding #edtech to the vocabulary\n","Adding #celebrate to the vocabulary\n","Adding #nollywood to the vocabulary\n","Adding #easterholiday to the vocabulary\n","Adding #smallbusiness to the vocabulary\n","Adding #relax to the vocabulary\n","Adding #liberals to the vocabulary\n","Adding #affirmations to the vocabulary\n","Adding #cryptocurrencies to the vocabulary\n","Adding #prayer to the vocabulary\n","Adding #photooftheday to the vocabulary\n","Adding #birding to the vocabulary\n","Adding #randomthoughts to the vocabulary\n","Adding #uae to the vocabulary\n","Adding #aavade to the vocabulary\n","Adding #ukrunchat to the vocabulary\n","Adding #heartbreakhill to the vocabulary\n","Adding #womenempowerment to the vocabulary\n","Adding #transformation to the vocabulary\n","Adding #strength to the vocabulary\n","Adding #runto126 to the vocabulary\n","Adding #sobriety to the vocabulary\n","Adding #veterans to the vocabulary\n","Adding #wellbeing to the vocabulary\n","Adding #steppingstrong to the vocabulary\n","Adding #fundraiser to the vocabulary\n","Adding #breaking to the vocabulary\n","Adding #newengland to the vocabulary\n","Adding #fanfest to the vocabulary\n","Adding #bostonbomber to the vocabulary\n","Adding #cysticfibrosis to the vocabulary\n","Adding #bostonredsox to the vocabulary\n","Adding #lasvegas to the vocabulary\n","Adding #runningcoach to the vocabulary\n","Adding #londonmarathon to the vocabulary\n","Adding #2021bostonmarathon to the vocabulary\n","Adding #teamjaf to the vocabulary\n","Adding #psychology to the vocabulary\n","Adding #president to the vocabulary\n","Adding #goodvibes to the vocabulary\n","Adding #melania to the vocabulary\n","Adding #themanwhofelltoearth to the vocabulary\n","Adding #sexeducation to the vocabulary\n","Adding #whitehouse to the vocabulary\n","Adding #blacklivesmatter to the vocabulary\n","Adding #indiaintimatefashionweek to the vocabulary\n","Adding #shortfilm to the vocabulary\n","Adding #momlife to the vocabulary\n","Adding #twh to the vocabulary\n","Adding #prek to the vocabulary\n","Adding #positivequotes to the vocabulary\n","Adding #readingcommunity to the vocabulary\n","Adding #teachertwitter to the vocabulary\n","Adding #creativity to the vocabulary\n","Adding #kindle to the vocabulary\n","Adding #parenting to the vocabulary\n","Adding #trendingnow to the vocabulary\n","Adding #writer to the vocabulary\n","Adding #school to the vocabulary\n","Adding #investing to the vocabulary\n","Adding #tranquility to the vocabulary\n","Adding #job to the vocabulary\n","Adding #brandnew to the vocabulary\n","Adding #toyosi to the vocabulary\n","Adding #giftmomart to the vocabulary\n","Adding #thisspringbuyart to the vocabulary\n","Adding #win to the vocabulary\n","Adding #thismankabogo to the vocabulary\n","Adding #musicmonday to the vocabulary\n","Adding #thrivetogether to the vocabulary\n","Adding #samsonsgreatadventures to the vocabulary\n","Adding #coffeetime to the vocabulary\n","Adding #rtartboost to the vocabulary\n","Adding #chivsmil to the vocabulary\n","Adding #genshinimapct to the vocabulary\n","Adding #genshin to the vocabulary\n","Adding #eldenring to the vocabulary\n","Adding #batmobile to the vocabulary\n","Adding #mood to the vocabulary\n","Adding #future to the vocabulary\n","Adding #filmtwitter to the vocabulary\n","Adding #sonicthehedgehog to the vocabulary\n","Adding #benaffleck to the vocabulary\n","Adding #uncharted to the vocabulary\n","Adding #thepenguin to the vocabulary\n","Adding #justiceleague to the vocabulary\n","Adding #ironman to the vocabulary\n","Adding #happyeaster2022 to the vocabulary\n","Adding #nyc to the vocabulary\n","Adding #aquaman to the vocabulary\n","Adding #fatherstu to the vocabulary\n","Adding #batfleck to the vocabulary\n","Adding #thekardashians to the vocabulary\n","Adding #treasure to the vocabulary\n","Adding #releasetheayercut to the vocabulary\n","Adding #arkhamknight to the vocabulary\n","Adding #virtualphotography to the vocabulary\n","Adding #digitalartist to the vocabulary\n","Adding #lego to the vocabulary\n","Adding #3d to the vocabulary\n","Adding #amc to the vocabulary\n","Adding #funko to the vocabulary\n","Adding #steelbook to the vocabulary\n","Adding #discovery to the vocabulary\n","Adding #filmmaking to the vocabulary\n","Adding #riverdale to the vocabulary\n","Adding #podernfamily to the vocabulary\n","Adding #abel to the vocabulary\n","Adding #lettheearthbreathe to the vocabulary\n","Adding #time to the vocabulary\n","Adding #doglovers to the vocabulary\n","Adding #nftartist to the vocabulary\n","Adding #theweeknddawnfm to the vocabulary\n","Adding #care to the vocabulary\n","Adding #finance to the vocabulary\n","Adding #thankyou to the vocabulary\n","Adding #xotwod to the vocabulary\n","Adding #bsc to the vocabulary\n","Adding #anatomyofascandal to the vocabulary\n","Adding #oscars2022 to the vocabulary\n","Adding #willowsmith to the vocabulary\n","Adding #atlanta to the vocabulary\n","Adding #humor to the vocabulary\n","Adding #nftdrops to the vocabulary\n","Adding #nftproject to the vocabulary\n","Adding #nftgiveaway to the vocabulary\n","Adding #trans to the vocabulary\n","Adding #france to the vocabulary\n","Adding #90dayfiancebefore90days to the vocabulary\n","Adding #author to the vocabulary\n","Adding #womenshistorymonth to the vocabulary\n","Adding #african to the vocabulary\n","Adding #investment to the vocabulary\n","Adding #ukrainerussianwar to the vocabulary\n","Adding #christian to the vocabulary\n","Adding #chocolate to the vocabulary\n","Adding #catholic to the vocabulary\n","Adding #longweekend to the vocabulary\n","Adding #drink to the vocabulary\n","Adding #thephotohour to the vocabulary\n","Adding #forsale to the vocabulary\n","Adding #biolab to the vocabulary\n","Adding #dubai to the vocabulary\n","Adding #hardrock to the vocabulary\n","Adding #dream to the vocabulary\n","Adding #vtuber to the vocabulary\n","Adding #questionoftheday to the vocabulary\n","Adding #happynewweek to the vocabulary\n","Adding #afl to the vocabulary\n","Adding #conservatives to the vocabulary\n","Adding #ghana to the vocabulary\n","Adding #wine to the vocabulary\n","Adding #paris to the vocabulary\n","Adding #hr to the vocabulary\n","Adding #recruitment to the vocabulary\n","Adding #altcoins to the vocabulary\n","Adding #vacation to the vocabulary\n","Adding #kindleunlimited to the vocabulary\n","Adding #mondayquote to the vocabulary\n","Adding #believe to the vocabulary\n","Adding #sport to the vocabulary\n","Adding #world to the vocabulary\n","Adding #seesomethingsaysomething to the vocabulary\n","Adding #inclusion to the vocabulary\n","Adding #teamultra to the vocabulary\n","Adding #nike to the vocabulary\n","Adding #puppy to the vocabulary\n","Adding #onebostonday to the vocabulary\n","Adding #marathons to the vocabulary\n","Adding #masters to the vocabulary\n","Adding #runningpodcast to the vocabulary\n","Adding #natick to the vocabulary\n","Adding #resilience to the vocabulary\n","Adding #empowerment to the vocabulary\n","Adding #nurses to the vocabulary\n","Adding #terrorism to the vocabulary\n","Adding #bpd to the vocabulary\n","Adding #unitedstates to the vocabulary\n","Adding #5k to the vocabulary\n","Adding #cambma to the vocabulary\n","Adding #vtpoli to the vocabulary\n","Adding #finishstrong to the vocabulary\n","Adding #texas to the vocabulary\n","Adding #writerscommunity to the vocabulary\n","Adding #honolulumarathon to the vocabulary\n","Adding #tcsnycmarathon to the vocabulary\n","Adding #patriots to the vocabulary\n","Adding #chicago to the vocabulary\n","Adding #winner to the vocabulary\n","Adding #bunsbosmarathon to the vocabulary\n","Adding #obama to the vocabulary\n","Adding #japan to the vocabulary\n","Adding #drunk to the vocabulary\n","Adding #thefirstladyonvoot to the vocabulary\n","Adding #swedenriots to the vocabulary\n","Adding #barackobama to the vocabulary\n","Adding #dakotafanning to the vocabulary\n","Adding #thefirstladytvseries to the vocabulary\n","Adding #jamespatterson to the vocabulary\n","Adding #casting to the vocabulary\n","Adding #soap to the vocabulary\n","Adding #goatmilksoap to the vocabulary\n","Adding #socialawareness to the vocabulary\n","Adding #boothetaboo to the vocabulary\n","Adding #crew to the vocabulary\n","Adding #hodl to the vocabulary\n","Adding #worldheritage to the vocabulary\n","Adding #growthmindset to the vocabulary\n","Adding #dragonoraclecard to the vocabulary\n","Adding #isrgkb to the vocabulary\n","Adding #tuesdaymotivation to the vocabulary\n","Adding #quotesdaily to the vocabulary\n","Adding #cybersecurity to the vocabulary\n","Adding #spirituality to the vocabulary\n","Adding #mainaandkingangi to the vocabulary\n","Adding #opportunity to the vocabulary\n","Adding #share to the vocabulary\n","Adding #worldheritageday2022 to the vocabulary\n","Adding #srinagar to the vocabulary\n","Adding #lifegoals to the vocabulary\n","Adding #santrampaljimaharajapp to the vocabulary\n","Adding #jammuandkashmir to the vocabulary\n","Adding #april2022 to the vocabulary\n","Adding #amritmahotsav to the vocabulary\n","Adding #quarantinelife to the vocabulary\n","Adding #famousquotes to the vocabulary\n","Adding #bollywood to the vocabulary\n","Adding #rome to the vocabulary\n","Adding #pharmtech to the vocabulary\n","Adding #nigerianswantgej to the vocabulary\n","Adding #mastermind to the vocabulary\n","Adding #ramzankashmir to the vocabulary\n","Adding #ramzanmubarak to the vocabulary\n","Adding #nba75 to the vocabulary\n","Adding #godnightmonday to the vocabulary\n","Adding #library to the vocabulary\n","Adding #earlychildhoodeducation to the vocabulary\n","Adding #envtuber to the vocabulary\n","Adding #dcu to the vocabulary\n","Adding #beach to the vocabulary\n","Adding #karma to the vocabulary\n","Adding #gamer to the vocabulary\n","Adding #pixelart to the vocabulary\n","Adding #superhero to the vocabulary\n","Adding #suicidesquad to the vocabulary\n","Adding #nascar to the vocabulary\n","Adding #bookmyshowstream to the vocabulary\n","Adding #mcfarlanetoys to the vocabulary\n","Adding #theadamproject to the vocabulary\n","Adding #novel to the vocabulary\n","Adding #colinfarrell to the vocabulary\n","Adding #escapeatdannemora to the vocabulary\n","Adding #captainmarvel to the vocabulary\n","Adding #watch to the vocabulary\n","Adding #thehungergames to the vocabulary\n","Adding #english to the vocabulary\n","Adding #christianbale to the vocabulary\n","Adding #eternals to the vocabulary\n","Adding #warnerbrosdiscovery to the vocabulary\n","Adding #pixeldailies to the vocabulary\n","Adding #tdkr to the vocabulary\n","Adding #turningred to the vocabulary\n","Adding #nightwing to the vocabulary\n","Adding #ps5 to the vocabulary\n","Adding #painting to the vocabulary\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"]},{"output_type":"execute_result","data":{"text/plain":["Embedding(31521, 768)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["\n","\n","train_inputs = tokenizer(train_text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n","train_inputs['labels'] = train_inputs.input_ids.detach().clone()\n","\n","test_inputs = tokenizer(test_text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n","test_inputs['labels'] = test_inputs.input_ids.detach().clone()"],"metadata":{"id":"tMA-ya5CKqNa","executionInfo":{"status":"ok","timestamp":1650345312700,"user_tz":300,"elapsed":151756,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["for i in range(len(test_inputs)):\n","  for j in range(128):\n","    test_inputs['attention_mask'][i][j] = 0\n","\n","for i in range(len(test_text)):\n","  for t in test_text[i].split():\n","\n","    if t in sp_tks:\n","      tks = tokenizer.encode(t, add_special_tokens=False)[0]\n","\n","      test_inputs['attention_mask'][i][test_inputs['input_ids'][i].tolist().index(tks)] = 1\n"],"metadata":{"id":"kHOcXILytkX6","executionInfo":{"status":"ok","timestamp":1650345545567,"user_tz":300,"elapsed":22608,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["class MeditationsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","\n","train_dataset = MeditationsDataset(train_inputs)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","test_dataset = MeditationsDataset(test_inputs)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)"],"metadata":{"id":"aN2wlnEMcaeu","executionInfo":{"status":"ok","timestamp":1650345581468,"user_tz":300,"elapsed":85,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# and move our model over to the selected device\n","model.to(device)\n","# activate training mode\n","model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSTM7ccfcgIt","executionInfo":{"status":"ok","timestamp":1650345583874,"user_tz":300,"elapsed":308,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"2a282b75-62d4-4389-8d2d-6eec4090f70d"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31521, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (transform_act_fn): GELUActivation()\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=768, out_features=31521, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["from transformers import AdamW\n","# initialize optimizer\n","optim = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHQArnirckgq","executionInfo":{"status":"ok","timestamp":1650345586474,"user_tz":300,"elapsed":111,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"72abb742-ab44-4e6c-c3da-5a57d3ae0c41"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm  # for our progress bar\n","\n","epochs = 2\n","\n","for epoch in range(epochs):\n","    # setup loop with TQDM and dataloader\n","    loop = tqdm(train_loader, leave=True)\n","    for batch in loop:\n","        # initialize calculated gradients (from prev step)\n","        optim.zero_grad()\n","        # pull all tensor batches required for training\n","        \n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        # process\n","        outputs = model(input_ids, attention_mask=attention_mask,\n","                        labels=labels)\n","        # extract loss\n","        loss = outputs.loss\n","        # calculate loss for every parameter that needs grad update\n","        loss.backward()\n","        # update parameters\n","        optim.step()\n","        # print relevant info to progress bar\n","        loop.set_description(f'Epoch {epoch}')\n","        loop.set_postfix(loss=loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XboMLwyWcm_E","executionInfo":{"status":"ok","timestamp":1650336132877,"user_tz":300,"elapsed":788439,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"6301ee92-0123-44e4-bb3f-83be4a140117"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1553 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","Epoch 0: 100%|██████████| 1553/1553 [06:34<00:00,  3.94it/s, loss=0.000315]\n","Epoch 1: 100%|██████████| 1553/1553 [06:34<00:00,  3.94it/s, loss=9.12e-5]\n"]}]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","batch_size = 16\n","training_args = TrainingArguments(\n","    output_dir='bert_twitter_hashtag',\n","    overwrite_output_dir=True,\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=2,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size\n","    # push_to_hub=True,\n","    # fp16=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEJzc8P1dJhP","executionInfo":{"status":"ok","timestamp":1650345589188,"user_tz":300,"elapsed":110,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"8f9e3831-f7b9-4dac-9594-da7d39e59599"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["! huggingface-cli login\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdGrux8lcpa1","executionInfo":{"status":"ok","timestamp":1650341821600,"user_tz":300,"elapsed":9284,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"54053e71-0ede-47d4-efd1-950edbb2d416"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens.\n","        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset\n",")"],"metadata":{"id":"LVC9cvrOfH4W","executionInfo":{"status":"ok","timestamp":1650345660530,"user_tz":300,"elapsed":123,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hh2Bx_8qkxkY","executionInfo":{"status":"ok","timestamp":1650346575383,"user_tz":300,"elapsed":913215,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"15cba6ea-be1c-4f2d-b7f0-e668887dcac5"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 24844\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3106\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3106' max='3106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3106/3106 15:12, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.000400</td>\n","      <td>0.002775</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.000200</td>\n","      <td>0.002858</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to bert_twitter_hashtag/checkpoint-500\n","Configuration saved in bert_twitter_hashtag/checkpoint-500/config.json\n","Model weights saved in bert_twitter_hashtag/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","Saving model checkpoint to bert_twitter_hashtag/checkpoint-1000\n","Configuration saved in bert_twitter_hashtag/checkpoint-1000/config.json\n","Model weights saved in bert_twitter_hashtag/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","Saving model checkpoint to bert_twitter_hashtag/checkpoint-1500\n","Configuration saved in bert_twitter_hashtag/checkpoint-1500/config.json\n","Model weights saved in bert_twitter_hashtag/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","***** Running Evaluation *****\n","  Num examples = 6211\n","  Batch size = 16\n","Saving model checkpoint to bert_twitter_hashtag/checkpoint-2000\n","Configuration saved in bert_twitter_hashtag/checkpoint-2000/config.json\n","Model weights saved in bert_twitter_hashtag/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","Saving model checkpoint to bert_twitter_hashtag/checkpoint-2500\n","Configuration saved in bert_twitter_hashtag/checkpoint-2500/config.json\n","Model weights saved in bert_twitter_hashtag/checkpoint-2500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","Saving model checkpoint to bert_twitter_hashtag/checkpoint-3000\n","Configuration saved in bert_twitter_hashtag/checkpoint-3000/config.json\n","Model weights saved in bert_twitter_hashtag/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","***** Running Evaluation *****\n","  Num examples = 6211\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3106, training_loss=0.06326158193563138, metrics={'train_runtime': 913.0388, 'train_samples_per_second': 54.42, 'train_steps_per_second': 3.402, 'total_flos': 3269568306825216.0, 'train_loss': 0.06326158193563138, 'epoch': 2.0})"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["import math\n","\n","eval_results = trainer.evaluate()\n","eval_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"uXW9ccRkiZ0n","executionInfo":{"status":"ok","timestamp":1650342830149,"user_tz":300,"elapsed":31184,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"cb2e1d00-9d6a-4908-9f26-6a30940223ca"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 6211\n","  Batch size = 16\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='389' max='389' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [389/389 00:30]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 2.0,\n"," 'eval_loss': 9.91832057479769e-05,\n"," 'eval_runtime': 30.9988,\n"," 'eval_samples_per_second': 200.362,\n"," 'eval_steps_per_second': 12.549}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["model.save_pretrained('./bert_twitter_hashtag/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zR1ahpPHXiDN","executionInfo":{"status":"ok","timestamp":1650346704504,"user_tz":300,"elapsed":1651,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"692ae0cb-d5f9-4376-91e6-c3546f1d50d8"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in ./bert_twitter_hashtag/config.json\n","Model weights saved in ./bert_twitter_hashtag/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["tokenizer.save_pretrained('./bert_twitter_hashtag/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRvKPI-Fzo_t","executionInfo":{"status":"ok","timestamp":1650346705528,"user_tz":300,"elapsed":320,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"2c5c4e0a-1862-457e-afa4-442829ff584a"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["tokenizer config file saved in ./bert_twitter_hashtag/tokenizer_config.json\n","Special tokens file saved in ./bert_twitter_hashtag/special_tokens_map.json\n","added tokens file saved in ./bert_twitter_hashtag/added_tokens.json\n"]},{"output_type":"execute_result","data":{"text/plain":["('./bert_twitter_hashtag/tokenizer_config.json',\n"," './bert_twitter_hashtag/special_tokens_map.json',\n"," './bert_twitter_hashtag/vocab.txt',\n"," './bert_twitter_hashtag/added_tokens.json')"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# trainer.push_to_hub()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"SOM5jd5Ii9VH","executionInfo":{"status":"error","timestamp":1650270672401,"user_tz":300,"elapsed":1839528,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"039e9bde-ff9f-4981-e438-03170e31e898"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to bert_twitter_hashtag\n","Configuration saved in bert_twitter_hashtag/config.json\n","Model weights saved in bert_twitter_hashtag/pytorch_model.bin\n","Several commits (3) will be pushed upstream.\n","The progress bars may be unreliable.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-8fcc5527db7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m         git_head_commit_url = self.repo.push_to_hub(\n\u001b[0;32m-> 2876\u001b[0;31m             \u001b[0mcommit_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_lfs_prune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m         )\n\u001b[1;32m   2878\u001b[0m         \u001b[0;31m# push separately the model card to be independant from the rest of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0mupstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"origin {self.current_branch}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0mauto_lfs_prune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_lfs_prune\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m         )\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mgit_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m                     \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m                     \u001b[0mreturn_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                     \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1713\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}